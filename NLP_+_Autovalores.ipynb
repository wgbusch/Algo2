{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP + Autovalores",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wgbusch/Algo2/blob/master/NLP_%2B_Autovalores.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aCKND09zxavl",
        "colab_type": "text"
      },
      "source": [
        "# Análisis de Sentimiento con KNN y PCA\n",
        "\n",
        "Vamos a usar el dataset de IMDB de [Maas et al(2011)](\n",
        "https://ai.stanford.edu/~amaas/data/sentiment/) \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYmw-hoew6ev",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://github.com/finiteautomata/imdb-dataset/raw/master/imdb_dataset.csv.zip\n",
        "!unzip imdb_dataset.csv.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x77gb_NyxYho",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd \n",
        "\n",
        "df = pd.read_csv(\"IMDB Dataset.csv\")\n",
        "\n",
        "\n",
        "print(\"Cantidad de documentos: {}\".format(df.shape[0]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YubaV3bd2Jd8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.options.display.max_colwidth = 200\n",
        "\n",
        "df[:3]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zdpK2UXK2tZX",
        "colab_type": "text"
      },
      "source": [
        "Lo mezclamos para que no esté ordenado"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7CNSqdF221f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Esto pide un sample, le pedimos una muestra de todo el df\n",
        "df = df.sample(frac=1)\n",
        "\n",
        "df[:3]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jz3AcySp25VD",
        "colab_type": "text"
      },
      "source": [
        "## Train y Test\n",
        "\n",
        "Nos vamos a quedar con una fracción de los datos para train y otra para test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JhJYdWnb3Lic",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sklearn\n",
        "\n",
        "df_train = df[:10000]\n",
        "df_test = df[10000:13000]\n",
        "\n",
        "text_train, text_test = df_train[\"review\"], df_test[\"review\"]\n",
        "label_train, label_test = df_train[\"sentiment\"], df_test[\"sentiment\"]\n",
        "\n",
        "print(\"Class balance : {} pos {} neg\".format(\n",
        "    (label_train == 'positive').sum() / label_train.shape[0], \n",
        "    (label_train == 'negative').sum() / label_train.shape[0]\n",
        "))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMhtW5pI3yE8",
        "colab_type": "text"
      },
      "source": [
        "Está más o menos parejo. Usemos accuracy (#cantidad de aciertos / #cantidad de ensayos) como métrica"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-Kfq3Lf4K-e",
        "colab_type": "text"
      },
      "source": [
        "## Convertir a bag of words\n",
        "\n",
        "Veamos cómo funciona CountVectorizer\n",
        "\n",
        "La idea general es que CountVectorizer convierte un conjunto de texto en el modelo de bolsa de palabras (bag of words), donde cada texto se representa como un vector de $\\mathbb{R}^V$, donde $V$ es el vocabulario elegido."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04SLlE4c4cz_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "textos = [\n",
        "    \"bolsa de palabras\",\n",
        "    \"bolsa es una palabra\",\n",
        "    \"palabra no es una bolsa\",\n",
        "]\n",
        "\n",
        "vect = CountVectorizer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nzmjNAYz9hA4",
        "colab_type": "text"
      },
      "source": [
        "Lo entramos a estos textos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFrgWAf_4oId",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vect.fit(textos)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkSsZNW04oo9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " vect.vocabulary_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8decO5qu4rNd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mat = vect.transform(textos)\n",
        "\n",
        "mat"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJ8i3MLq4uUU",
        "colab_type": "text"
      },
      "source": [
        "Es una matriz \"rala\" (ESPARSA NO ES UNA PALABRA DE ESPAÑOL)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKOkmVgE4zWz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mat = mat.todense()\n",
        "\n",
        "mat"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1PQdgcLJ41Mx",
        "colab_type": "text"
      },
      "source": [
        "Ahora, apliquemos esto a nuestros textos...\n",
        "\n",
        "No nos vamos a quedar con todas las palabras:\n",
        "\n",
        "- Sacar palabras muy frecuentes\n",
        "- Sacar palabras que aparecen muy pocas veces \n",
        "\n",
        "¿Por qué sirve esto?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYF7LwOd49vz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vect = CountVectorizer()\n",
        "\n",
        "vect.fit(text_train)\n",
        "\n",
        "len(vect.vocabulary_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GLghxs6b8LOE",
        "colab_type": "text"
      },
      "source": [
        "Esto es un montón. Reduzcámoslo un poco"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ch4SfSY5NdX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vect = CountVectorizer(min_df=3, max_features=5000)\n",
        "\n",
        "vect.fit(text_train)\n",
        "\n",
        "len(vect.vocabulary_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FiYawk8Y5gs0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = vect.transform(text_train)\n",
        "X_test = vect.transform(text_test)\n",
        "\n",
        "y_train = label_train# == 'positive' # Convertimos a vectores booleanos\n",
        "y_test = label_test# == \"positive\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqBlZHPH55iO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "clf = KNeighborsClassifier(50)\n",
        "\n",
        "clf.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RjzpXkva6Am_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "from sklearn.metrics import accuracy_score\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy: {}\".format(acc))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E4u2V4-S6EQw",
        "colab_type": "text"
      },
      "source": [
        "¿Podremos mejorarlo...?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PpSSXe9B_xvA",
        "colab_type": "text"
      },
      "source": [
        "## Metodo de la potencia\n",
        "\n",
        "Implementar las siguientes funciones (`power_iteration` y `eig`)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4lRE4Kn_zdZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def power_iteration(A, niter=10000, eps):\n",
        "    \"\"\"\n",
        "    Calcula el autovector al autovalor asociado de valor máximo\n",
        "    \n",
        "    \n",
        "    Devuelve (a, v) con a autovalor, y v autovector de A\n",
        "    \"\"\"\n",
        "    \n",
        "    a = 1\n",
        "    v = np.ones(A.shape[0])\n",
        "    \n",
        "    return a, v\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGhKPPcm_5qB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "D = np.diag([5.0, 4.0, 3.0, 2.0, 1.0])\n",
        "\n",
        "v = np.ones((D.shape[0], 1))\n",
        "\n",
        "v = v / np.linalg.norm(v)\n",
        "\n",
        "# Matriz de Householder\n",
        "B = np.eye(D.shape[0]) - 2 * (v @ v.T)\n",
        "\n",
        "# Matriz ya diagonalizada\n",
        "M = B.T @ D @ B\n",
        "\n",
        "power_iteration(M)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWYuBwdtB9hA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def eig(A, num=2, niter=10000, eps=1e-6):\n",
        "    \"\"\"\n",
        "    Calculamos num autovalores y autovectores usando método de la potencia+deflación\n",
        "    \"\"\"\n",
        "    A = A.copy()\n",
        "    eigenvalues = []\n",
        "    eigenvectors = np.zeros((A.shape[0], num))\n",
        "    for i in range(num):\n",
        "        \"\"\"\n",
        "        TODO: Completar código\n",
        "        \"\"\"\n",
        "        pass    \n",
        "    return np.array(eigenvalues), eigenvectors\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGYFi1v3C1Ne",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}